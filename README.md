# PROYECTO DE TERCER CORTE CORREGIDO
RODIAN GARAY Y MARIANA LOMBANA 


# Descripci√≥n General

El objetivo principal del primer m√≥dulo del proyecto es desarrollar un sistema automatizado capaz de obtener al menos 200 im√°genes de distintas herramientas usadas en los laboratorios de ingenier√≠a electr√≥nica, tales como:
- Raspberry Pi
- Generador de se√±ales
- Osciloscopio
- Fuente dual
- Destornillador
- Pinzas
- Condensador
- Transistor
- Bombilla

Este conjunto de im√°genes servir√° como base de datos visual para las siguientes fases del proyecto (ETL, clasificaci√≥n y despliegue).
Para asegurar un alto rendimiento, el sistema usa:
- Hilos (threads) para ejecutar m√∫ltiples b√∫squedas en paralelo
- Sem√°foro para controlar cu√°ntos navegadores se abren al mismo tiempo
- Mutex (Lock) para evitar errores al escribir archivos en disco
- Selenium + WebDriver Manager para realizar b√∫squedas reales en Mercado Libre

# Arquitectura del Sistema de Scraping

El sistema est√° construido bajo un modelo de concurrencia que coordina:
- Un hilo principal que organiza las tareas
- Varios hilos trabajadores que realizan el scraping
- Un mecanismo bloqueante que protege las descargas
- Cada hilo procesa un producto, abre un navegador (si el sem√°foro lo permite), obtiene enlaces de im√°genes y los env√≠a al descargador. Este √∫ltimo guarda los archivos asegurando que no ocurran colisiones.

```mermaid
flowchart TD
    CORE((Motor de Scraping))

    CTRL[Hilo Controlador]
    EXEC[Hilos Ejecutores x10]
    SAFE[Modulo de Descarga Segura]

    A1[Genera listado de categor√≠as]
    A2[Coordina y distribuye tareas]

    B1[Solicita acceso por sem√°foro]
    B2[Inicia navegador Selenium]
    B3[Recolecta enlaces de im√°genes]
    B4[Entrega enlaces al m√≥dulo de descarga]

    C1[Realiza descarga HTTP]
    C2[Usa Lock para evitar conflictos]
    C3[Organiza y almacena archivos]

    CORE --> CTRL
    CORE --> EXEC
    CORE --> SAFE

    CTRL --> A1
    CTRL --> A2

    EXEC --> B1
    EXEC --> B2
    EXEC --> B3
    EXEC --> B4

    SAFE --> C1
    SAFE --> C2
    SAFE --> C3

    CTRL --> EXEC --> SAFE

```


##  Tecnolog√≠as Utilizadas


| Tecnolog√≠a            | Funci√≥n                                      |
| --------------------- | -------------------------------------------- |
| **Python 3**          | Base l√≥gica del programa                     |
| **Selenium**          | Captura de im√°genes mediante navegaci√≥n real |
| **WebDriver Manager** | Administra el driver de Chrome               |
| **Requests**          | Descarga de archivos                         |
| **Threads**           | Procesamiento paralelo                       |
| **Semaphore**         | Control de navegadores abiertos              |
| **Lock/Mutex**        | Protecci√≥n en escritura a disco              |


# Modelo de Concurrencia
## Hilos
Cada producto se procesa en un hilo independiente, lo que permite descargar im√°genes simult√°neamente.
## Sem√°foro
Para evitar abrir demasiados navegadores a la vez, solo se permiten 3 Chrome simult√°neos para no afectar la ram:
```
browser_semaphore = threading.Semaphore(3)
```
## Mutex

Cuando varios archivos se descragar simultaneamente se puede generar archovos corrupos, colisiones o directorios bloqueados para eso, solo un hilo puede escribir en disco para evitar da√±os o conflictos:
```
with file_lock:
    with open(filename, "wb") as f:
        f.write(img.content)
```
## Estructura Final 

El scraping genera una carpeta:
```
scraping/images/
    raspberry/
    osciloscopio/
    generador_de_senales/
    transistor/
    bombilla/
    ...
```

# C√≥digo utilizado para el scraping

```
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import threading
import os
import time
import requests

# ============================
# CONFIGURACI√ìN GENERAL
# ============================
BASE_DIR = "scraping/images/"
os.makedirs(BASE_DIR, exist_ok=True)

productos = [
    "multimetro", "raspberry", "generador de se√±ales", "osciloscopio",
    "fuente dual", "destornillador", "pinzas", "condensador",
    "transistor", "bombilla"
]

file_lock = threading.Lock()
browser_semaphore = threading.Semaphore(3)  # 3 navegadores m√°ximo

# ============================
# DRIVER
# ============================
def iniciar_driver():
    opt = webdriver.ChromeOptions()
    opt.add_argument("--headless")
    opt.add_argument("--window-size=1920,1080")
    opt.add_argument("--disable-dev-shm-usage")
    opt.add_argument("--no-sandbox")
    return webdriver.Chrome(
        service=Service(ChromeDriverManager().install()),
        options=opt
    )

# ============================
# DESCARGA SEGURA
# ============================
def descargar_imagen(url, destino):
    try:
        contenido = requests.get(url, timeout=5).content

        with file_lock:
            with open(destino, "wb") as archivo:
                archivo.write(contenido)

    except:
        pass

# ============================
# FUNCI√ìN PRINCIPAL DEL HILO
# ============================
def scrapear(producto):
    with browser_semaphore:

        driver = iniciar_driver()
        driver.get(f"https://listado.mercadolibre.com.co/{producto}")
        time.sleep(3)

        altura = driver.execute_script("return document.body.scrollHeight")
        for _ in range(6):
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1.8)
            nueva_altura = driver.execute_script("return document.body.scrollHeight")
            if nueva_altura == altura:
                break
            altura = nueva_altura

        carpeta_producto = os.path.join(BASE_DIR, producto.replace(" ", "_"))
        os.makedirs(carpeta_producto, exist_ok=True)

        imagenes = driver.find_elements(By.TAG_NAME, "img")
        contador = 0

        for imagen in imagenes:
            src = (
                imagen.get_attribute("src")
                or imagen.get_attribute("data-src")
                or imagen.get_attribute("srcset")
            )

            if src and "http" in src:
                if "srcset" in src:
                    src = src.split(" ")[0]

                destino = os.path.join(carpeta_producto, f"{producto}_{contador}.jpg")
                descargar_imagen(src, destino)
                contador += 1

            if contador >= 200:
                break

        driver.quit()
        print(f"‚úî {producto} ‚Üí {contador} im√°genes descargadas.")

# ============================
# HILOS
# ============================
hilos = []
for prod in productos:
    t = threading.Thread(target=scrapear, args=(prod,))
    t.start()
    hilos.append(t)

for t in hilos:
    t.join()

print("\nFINALIZADO\n")

``` 
Este script paso a paso :

 1. Abre Mercado Libre
 2. Busca cada producto
 3. Descarga hasta 200 im√°genes por categor√≠a
 4. Crea carpetas autom√°ticamente
 5. Usa Selenium + Hilos de forma profesional

# Estructura de Salida del Scraping

Una vez ejecutado, autom√°ticamente se genera la carpeta y enumera cada imagen en orden de esta forma:
```
scraping/
‚îÇ
‚îî‚îÄ‚îÄ images/
    ‚îú‚îÄ‚îÄ raspberry/
    ‚îÇ     ‚îú‚îÄ‚îÄ img_001.jpg
    ‚îÇ     ‚îú‚îÄ‚îÄ img_002.jpg
    ‚îÇ     ‚îî‚îÄ‚îÄ ...
    ‚îú‚îÄ‚îÄ osciloscopio/
    ‚îú‚îÄ‚îÄ generador de se√±ales/
    ‚îú‚îÄ‚îÄ transistor/
    ‚îú‚îÄ‚îÄ bombilla/
    ‚îî‚îÄ‚îÄ ...
```

Cada carpeta contiene 200 im√°genes limpias obtenidas desde la web.

# Ejecucion paso a paso 

## 1. Ingresar a powershell 
 <img width="955" height="502" alt="1" src="https://github.com/user-attachments/assets/8dcdff8c-97e0-44c8-8e2a-77dd1d24050e" />
## 2. Se crea un entorno virtual 
 <img width="959" height="502" alt="2" src="https://github.com/user-attachments/assets/c820dafe-d584-45d0-9752-a07e490be93a" />
## 3. Se instalan librerias necesarias 
 <img width="1895" height="804" alt="image" src="https://github.com/user-attachments/assets/6c150a27-0c93-4106-b4a4-3a1682168b20" />
## 4. Se ejecuta el archivo scraper
 <img width="817" height="545" alt="image" src="https://github.com/user-attachments/assets/489c66b9-811d-4cc4-bd5b-72e75f839f11" />
## 5. Se crea una carpeta llamada imagenes con todas las carpetas de imagemes
 <img width="1919" height="1010" alt="image" src="https://github.com/user-attachments/assets/97807015-3243-4adb-b489-c01b50cf05f2" />
## 6. Cada una cuenta con 200 imagenes como se evidencia en esta:
 <img width="1919" height="1005" alt="image" src="https://github.com/user-attachments/assets/61e71216-071f-4895-9b62-8579229b2a96" />

# Conclusi√≥n del Punto 1

El sistema desarrollado cumple todos los requerimientos establecidos:

- Web Scraping con Selenium
- B√∫squeda de m√°s de 10 elementos electr√≥nicos
- Descarga masiva de m√°s de 200 im√°genes por categor√≠a
- Uso expl√≠cito y correcto de:

Hilos

Secci√≥n cr√≠tica

Sem√°foro

Mutex

- Arquitectura profesional lista para ETL, clasificaci√≥n e integraci√≥n en Docker
- Documentaci√≥n clara y t√©cnica para evaluaci√≥n acad√©mica

Este punto es la base del proyecto completo, permitiendo construir la base de im√°genes que alimentar√° el modelo de clasificaci√≥n (punto 2) y el sistema de detecci√≥n en tiempo real (puntos 3 y 4).

# PUNTO 2 ‚Äî Desarrollo Completo del ETL (Extracci√≥n, Transformaci√≥n y Carga)

El objetivo del Punto 2 es crear una Base de Datos completamente funcional, dise√±ada para almacenar las 200 im√°genes por clase obtenidas en el scraping, manteniendo orden, trazabilidad y soporte para el modelo de clasificaci√≥n y dem√°s puntos del proyecto.
## Este apartado documenta:
- Dise√±o del modelo relacional
- Creaci√≥n de la base de datos
- Tablas y relaciones
- Carga masiva automatizada de las im√°genes
- Evidencias del correcto funcionamiento
- Estructura final del sistema

# 2.1. Objetivo del M√≥dulo de Base de Datos

La base de datos debe permitir:
- Registrar cada clase (raspberry, osciloscopio, etc.).
- Registrar las 200 im√°genes procesadas por clase.
- Guardar metadatos √∫tiles para el modelo (ruta, tama√±o, hash, fecha).
- Evitar duplicados.
- Integrarse con el ETL y con el clasificador.
- Consultar f√°cilmente el dataset completo.

Para este proyecto se us√≥ SQLite porque:

- No requiere servido
- Es portable
- Funciona en cualquier entorno, incluyendo Docker}
- Perfecto para datasets ligeros

# 2.2. Modelo Relacional de la Base de Datos

El sistema se basa en dos tablas principales:

## 1. Tabla clases

Contiene las categor√≠as del dataset.

| Campo       | Tipo        | Descripci√≥n                          |
| ----------- | ----------- | ------------------------------------ |
| id          | INTEGER PK  | ID √∫nico                             |
| nombre      | TEXT UNIQUE | Nombre de la clase (ej: "raspberry") |
| descripcion | TEXT        | Descripci√≥n opcional                 |

## 2. Tabla imagenes

Registra cada imagen del scraping o del ETL.

| Campo          | Tipo       | Descripci√≥n                     |
| -------------- | ---------- | ------------------------------- |
| id             | INTEGER PK | ID √∫nico                        |
| clase_id       | INTEGER FK | Relaci√≥n con clase              |
| ruta           | TEXT       | Ruta del archivo en el sistema  |
| hash           | TEXT       | Hash MD5 para evitar duplicados |
| ancho          | INTEGER    | Ancho en px                     |
| alto           | INTEGER    | Alto en px                      |
| fecha_registro | TEXT       | Fecha de inserci√≥n              |

## Diagrama relacional
```
clases (1)  -------------------  (N) imagenes
      id   <------------------   clase_id
```
# 2.3. Creaci√≥n de la Base de Datos
## Se crea la carpeta para la pase de datos 
<img width="1105" height="67" alt="image" src="https://github.com/user-attachments/assets/cfa3d7db-8633-48ac-99cc-f7a204cc9744" />
## Se ingresa a la carpeta y se verifica que este vacia 
<img width="1237" height="287" alt="image" src="https://github.com/user-attachments/assets/cd96f58a-9bbf-425f-9527-6996b09239bb" />
## Se crea el archivo dataset para crear las tablas 
<img width="1082" height="130" alt="image" src="https://github.com/user-attachments/assets/f75713ff-2319-44ca-9c21-8275f26aa8ac" />
## Se crea base de datos
<img width="1305" height="78" alt="image" src="https://github.com/user-attachments/assets/a1afc74f-38b7-4cb7-a9bd-633d383ac86f" />
```
import sqlite3
conn = sqlite3.connect("dataset.db")
cur = conn.cursor()

cur.execute("""
CREATE TABLE IF NOT EXISTS clases (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    nombre TEXT UNIQUE NOT NULL,
    descripcion TEXT
);
""")

cur.execute("""
CREATE TABLE IF NOT EXISTS imagenes (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    clase_id INTEGER NOT NULL,
    ruta TEXT NOT NULL,
    hash TEXT NOT NULL UNIQUE,
    ancho INTEGER,
    alto INTEGER,
    fecha_registro TEXT,
    FOREIGN KEY(clase_id) REFERENCES clases(id)
);
""")

conn.commit()
conn.close()
print("‚úî Base de datos creada exitosamente")

```
## Se crea las clases 
<img width="1313" height="386" alt="image" src="https://github.com/user-attachments/assets/21fd71f9-4b8d-4b79-a429-af1408885406" />
```
import sqlite3

DB_PATH = "dataset.db"

clases = [
    ("bombilla", "Dispositivo de iluminaci√≥n"),
    ("condensador", "Componente que almacena energ√≠a"),
    ("destornillador", "Herramienta manual para tornillos"),
    ("fuente_dual", "Fuente de alimentaci√≥n dual"),
    ("generador_de_senales", "Generador de se√±ales electr√≥nica"),  # SIN √ë
    ("multimetro", "Instrumento de medici√≥n el√©ctrica"),
    ("osciloscopio", "Instrumento para visualizar se√±ales"),
    ("pinzas", "Herramienta para manipular componentes"),
    ("raspberry", "Computadora de placa reducida"),
    ("transistor", "Componente semiconductor de tres terminales")
]

conn = sqlite3.connect(DB_PATH)
cur = conn.cursor()

print("Insertando clases en la base de datos...\n")

for clase, desc in clases:
    try:
        cur.execute("INSERT INTO clases (nombre, descripcion) VALUES (?, ?)", (clase, desc))
        print(f"‚úî Clase insertada: {clase}")
    except sqlite3.IntegrityError:
        print(f"‚ö† Clase ya exist√≠a: {clase}")

conn.commit()
conn.close()

print("\n‚úî Inserci√≥n completa")

```
## Se crea la carga de imagenes 
<img width="1918" height="723" alt="image" src="https://github.com/user-attachments/assets/3160e5a4-b3a6-4a9d-a69c-b474b6e8f00b" />
```
import sqlite3
import os
import cv2
import hashlib
from datetime import datetime

# ==============================
# CONFIGURACI√ìN
# ==============================

DB_PATH = "dataset.db"

# Ruta con tus 10 carpetas de im√°genes
IMAGES_ROOT = r"C:/Users/Lenovo/Desktop/Proyecto final 2/1. Primer punto/scraping/images/"

# ==============================
# FUNCIONES AUXILIARES
# ==============================

def calcular_hash(path):
    """Genera hash MD5 √∫nico por imagen."""
    try:
        with open(path, "rb") as f:
            return hashlib.md5(f.read()).hexdigest()
    except:
        return None


def get_image_size(path):
    """Obtiene dimensiones de la imagen."""
    try:
        img = cv2.imread(path)
        if img is None:
            return None, None
        h, w = img.shape[:2]
        return w, h
    except:
        return None, None

# ==============================
# CONEXI√ìN A LA BD
# ==============================

conn = sqlite3.connect(DB_PATH)
cur = conn.cursor()

print("üìå Conectado a la base de datos")

cur.execute("SELECT id, nombre FROM clases")
clases_db = {nombre: cid for cid, nombre in cur.fetchall()}

print("üìå Clases detectadas:", clases_db)

# ==============================
# RECORRER TODAS LAS CARPETAS
# ==============================

insertados_total = 0

for clase_nombre, clase_id in clases_db.items():
    carpeta = os.path.join(IMAGES_ROOT, clase_nombre)

    if not os.path.exists(carpeta):
        print(f"‚ö† La carpeta '{carpeta}' no existe. Saltando...")
        continue

    print(f"\nüîé Procesando clase: {clase_nombre}")

    for archivo in os.listdir(carpeta):
        ruta_img = os.path.join(carpeta, archivo)

        if not ruta_img.lower().endswith((".jpg", ".jpeg", ".png")):
            continue

        hash_img = calcular_hash(ruta_img)

        if hash_img is None:
            print(f"‚ùå Error leyendo: {ruta_img}")
            continue

        w, h = get_image_size(ruta_img)
        fecha = datetime.now().isoformat()

        try:
            cur.execute("""
                INSERT INTO imagenes (clase_id, ruta, hash, ancho, alto, fecha_registro)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (clase_id, ruta_img, hash_img, w, h, fecha))

            insertados_total += 1

        except sqlite3.IntegrityError:
            print(f"‚ö† Imagen duplicada: {ruta_img}")
            continue

conn.commit()
conn.close()

print("\n‚úî PROCESO FINALIZADO ‚úî")
print(f" Total de im√°genes insertadas: {insertados_total}")

```

## 2.3.1. ¬øC√≥mo detecta la aplicaci√≥n si una imagen es buena o mala?
Tu aplicaci√≥n considera que una imagen es buena cuando:
- La imagen puede abrirse
Usamos esta l√≠nea:
```
img = cv2.imread(path)
```

Si img es None, OpenCV no pudo leerla ‚Üí imagen da√±ada o no v√°lida.

- La imagen tiene ancho y alto

Si cv2.imread() s√≠ logra leerla:
```
h, w = img.shape[:2]
```

Si shape no existe, la imagen es mala.

üî¥ ¬øQu√© ocurre con una imagen mala o da√±ada?

cv2.imread() devuelve None

El programa muestra:

‚ùå Error leyendo: ruta_de_la_imagen


Esa imagen no se inserta en la base de datos

Por eso tu BD queda limpia: solo im√°genes v√°lidas entran.

‚úÖ 2. ¬øC√≥mo detecta la aplicaci√≥n im√°genes repetidas?

El sistema usa un hash MD5, que es una especie de ‚Äúhuella digital‚Äù √∫nica generada a partir del contenido de la imagen.

En el c√≥digo:

hashlib.md5(f.read()).hexdigest()


Esto significa:

Si 2 im√°genes son id√©nticas, su MD5 ser√° exactamente igual

Si una imagen cambia 1 solo pixel, tendr√° un hash diferente

üîç ¬øC√≥mo se evita insertar duplicados?

En la tabla imagenes, definimos:

hash TEXT NOT NULL UNIQUE


Eso significa que no se pueden repetir hashes.

Cuando el script intenta insertar una imagen repetida:

cur.execute(...)


SQLite encuentra que el hash ya existe ‚Üí lanza:

sqlite3.IntegrityError


Y nuestro c√≥digo captura esto:

print(f"‚ö† Imagen duplicada: {ruta_img}")


y NO inserta la imagen duplicada.



  
# Arquitectura General del ETL

El pipeline se divide en 3 m√≥dulos principales:

Extracci√≥n ‚Üí obtenci√≥n de im√°genes desde el directorio de scraping.

Transformaci√≥n ‚Üí limpieza, validaci√≥n y preprocesamiento de cada imagen.

Carga ‚Üí almacenamiento ordenado en directorios por clase + exportaci√≥n de metadat

# 2.1. M√≥dulo de Extracci√≥n

Objetivo: Leer todas las im√°genes descargadas en el punto 1 y validarlas previo al procesamiento.

 Se recorren las carpetas generadas por el scraping:

scraping/images/<nombre_de_clase>/


 Se cuentan todas las im√°genes de cada categor√≠a.
 Se detectan archivos da√±ados mostrando advertencias como:

 # 2.2. M√≥dulo de Transformaci√≥n

Este m√≥dulo ejecuta:

 1. Limpieza y validaci√≥n

Se intenta abrir cada imagen con OpenCV.

Si falla ‚Üí se descarta autom√°ticamente.

Se evita cargar im√°genes con tama√±o incorrecto o corruptas.

# 2.3 Estandarizaci√≥n

Cada imagen se transforma mediante:

Redimensionamiento a 224√ó224 px.

Normalizaci√≥n de valores entre 0 y 1.

Conversi√≥n a formato .npy optimizado para ML.

Generaci√≥n de un hash MD5 por imagen
Esto permite:

Detectar duplicados

Evitar procesar im√°genes repetidas

Mantener un dataset limpio y sin ruido

 Aqu√≠ insertas la imagen donde se muestran los duplicados omitidos:

Ejemplo del mensaje real:
 ```python
 Duplicado omitido (hash repetido): etl/data/processed/transistor/transistor_90.jpg.npy
```

# 3. Manejo multihilo (threads)

Para acelerar el proceso, cada clase se procesa en paralelo:

Un hilo por categor√≠a (raspberry, osciloscopio, fuente, etc.)

Mutex para operaciones cr√≠ticas

Sincronizaci√≥n de escritura en disco

Esto reduce radicalmente el tiempo total del ETL.

# 2.3. M√≥dulo de Carga

Luego de validar y transformar todas las im√°genes:

 Se guardan las im√°genes limpias en:
etl/data/processed/<nombre_de_clase>/

 Se registran estad√≠sticas globales:

N√∫mero de im√°genes finales por categor√≠a

Total final del dataset

N√∫mero de duplicados eliminados

Im√°genes descartadas por corrupci√≥n

 Aqu√≠ insertas tu imagen donde se ve la finalizaci√≥n con total 1850 im√°genes:

Ejemplo real:

 Clase 'transistor' cargada correctamente.
 Carga finalizada. Total im√°genes registradas: 1850

# Estructura final generada

etl/
 ‚îú‚îÄ‚îÄ data/
 ‚îÇ    ‚îú‚îÄ‚îÄ raw/
 ‚îÇ    ‚îú‚îÄ‚îÄ processed/
 ‚îÇ    ‚îÇ     ‚îú‚îÄ‚îÄ raspberry/
 ‚îÇ    ‚îÇ     ‚îú‚îÄ‚îÄ osciloscopio/
 ‚îÇ    ‚îÇ     ‚îú‚îÄ‚îÄ transistor/
 ‚îÇ    ‚îÇ     ‚îú‚îÄ‚îÄ generador_de_se√±ales/
 ‚îÇ    ‚îÇ     ‚îî‚îÄ‚îÄ ‚Ä¶
 ‚îÇ    ‚îî‚îÄ‚îÄ metadata.json
 ‚îú‚îÄ‚îÄ etl_extract.py
 ‚îú‚îÄ‚îÄ etl_transform.py
 ‚îî‚îÄ‚îÄ etl_load.py

 # C√≥digo del ETL (resumen t√©cnico)
 Transformaci√≥n (etl_transform.py)
  ```python
# Procesamiento: resize, normalizaci√≥n y hash
image = cv2.resize(image, (224, 224))
image = image.astype("float32") / 255.0

hash_value = hashlib.md5(image.tobytes()).hexdigest()

output_path = f"{processed_dir}/{filename}.npy"
np.save(output_path, image)
 ```

 Carga (etl_load.py)
 ```python
if hash_value in hash_registry[class_name]:
    print(f"‚ö†Ô∏è Duplicado omitido (hash repetido): {output_file}")
else:
    hash_registry[class_name].add(hash_value)
    np.save(output_file, image)
 ```

 Conclusiones del ETL

El dataset qued√≥ completamente limpio, sin archivos corruptos.

Se eliminaron centenas de im√°genes duplicadas mediante hashing.

El proceso final contiene 1850 im√°genes v√°lidas, perfectas para entrenamiento.

La arquitectura ETL es profesional, modular y escalable, lista para integrarse con el modelo del Punto 3.

# Im√°genes

<img width="876" height="437" alt="image" src="https://github.com/user-attachments/assets/1e53dcbe-7128-4060-a0f9-eaa577819b9b" />










# PUNTO 3 ‚Äî Sistema de Clasificaci√≥n de Objetos + Detecci√≥n y Velocidad de Personas (Modelo Simple + OpenCV HOG + Multithreading)

El tercer punto del proyecto implementa un sistema completo de visi√≥n artificial en tiempo real que:

Clasifica herramientas de laboratorio usando un modelo propio entrenado con el dataset del ETL.

Detecta personas, genera identificaci√≥n por ID y calcula su velocidad instant√°nea.

Corre dos an√°lisis paralelos (objetos y velocidad) usando la misma c√°mara, gracias a hilos, sem√°foros y locks.

Despliega todo el sistema dentro de una aplicaci√≥n Streamlit con dos pesta√±as interactivas.

La arquitectura final combina procesamiento de im√°genes, machine learning simple, detecci√≥n HOG, tracking, sincronizaci√≥n por hilos y Streamlit, integrando todo en un entorno estable y profesional.

#  Arquitectura General del Punto 3

El sistema est√° compuesto por 3 hilos principales:

CamGrabber ‚Üí productor de frames (un solo hilo para toda la app)

PredictorThread ‚Üí clasifica herramientas con el modelo entrenado

PeopleSpeedThread ‚Üí detecta personas, les asigna ID y calcula velocidad

Cada uno opera de forma independiente, pero sincronizados mediante:

Locks ‚Üí para acceso seguro a los frames compartidos

Sem√°foros ‚Üí para controlar el procesamiento simult√°neo de predicciones

Threads Daemon ‚Üí para ejecutar tareas en paralelo sin bloquear la UI

# 3.1. Captura de C√°mara ‚Äì Hilo CamGrabber

Este hilo es el coraz√≥n de la app:
- captura continuamente los frames de la webcam
- los entrega al predictor y al m√≥dulo de velocidad
  - calcula FPS en tiempo real
 ```python
self.lock = threading.Lock()
self.frame = None

ret, frame = self.cap.read()
with self.lock:
    self.frame = frame.copy()
 ```

Ventajas:

Evita capturas duplicadas

Garantiza que todos los hilos usan el mismo frame sincronizado

Minimiza consumo de CPU y evita retardos


 <img width="730" height="525" alt="image" src="https://github.com/user-attachments/assets/b2dfa864-5b3c-47db-bee8-916d6e451bd3" />


# 3.2. Clasificaci√≥n de Objetos ‚Äì Hilo PredictorThread

Este m√≥dulo usa el modelo entrenado en el Punto 2:

modelo lineal con pesos W y b

extracci√≥n de caracter√≠sticas manual con kernels

clasificaci√≥n sin umbral (siempre muestra la predicci√≥n)

 Pipeline del predictor:

Convertir frame a escala de grises

Redimensionar a 256√ó256

Normalizar

Extraer caracter√≠sticas mediante 3 kernels

Aplicar pooling

Normalizar vector de caracter√≠sticas

Multiplicar por W y sumar b

Aplicar softmax

Ejemplo de predicci√≥n overlay:
```python

text = f"{pred_t.pred} ({pred_t.conf:.2f})"
cv2.putText(frame_obj, text, (20,50), ...)

```
<img width="619" height="823" alt="image" src="https://github.com/user-attachments/assets/1a64d7f0-a8c7-4bcb-8e7f-f466677b3ddc" />
<img width="663" height="813" alt="image" src="https://github.com/user-attachments/assets/412e8f0d-a06c-448b-a82a-86f622607dc4" />
<img width="632" height="737" alt="image" src="https://github.com/user-attachments/assets/c2bc143b-eeb9-443a-b4d1-5e75cdf60785" />


3.3. Detecci√≥n de Personas + Velocidad ‚Äì Hilo PeopleSpeedThread

Este m√≥dulo implementa:

Detector HOG de OpenCV (cv2.HOGDescriptor)

Asignaci√≥n de IDs por cercan√≠a de centroides

Memoria de √∫ltimos frames

C√°lculo de velocidad por persona

Eliminaci√≥n de tracks desaparecidos

##  C√°lculo de Velocidad del Objeto

La velocidad se calcula como:

**velocidad (px/s) = Œîdistancia(px) / Œîtiempo(s)**

Donde:

- **Œîdistancia(px)** = diferencia del centroide entre dos frames.
- **Œîtiempo(s)** = tiempo transcurrido entre capturas consecutivas.

### F√≥rmula utilizada

**distancia_px = ‚àö((x‚ÇÇ - x‚ÇÅ)¬≤ + (y‚ÇÇ - y‚ÇÅ)¬≤)**  
**velocidad = distancia_px / dt**

### Implementaci√≥n en Python

```python
dist_px = ((cx - prev["centroid"][0])**2 + (cy - prev["centroid"][1])**2)**0.5
speed = dist_px / dt

```
# 3.4. Multithreading: Locks + Sem√°foros
Locks

Usados para evitar corrupci√≥n de memoria y lectura simult√°nea del frame.
```python
with self.lock:
    self.frame = frame.copy()
```
 Sem√°foros

Controlan cu√°ntas predicciones simult√°neas puede hacer el predictor.
```python
self.sema = threading.Semaphore(1)
```

Esto evita:

saturaci√≥n del CPU

bloqueos en la lectura de la c√°mara

predicciones repetidas sobre el mismo frame

# 3.5. Interfaz Streamlit con Pesta√±as Din√°micas

La app presenta dos vistas en tiempo real:

 Pesta√±a 1: ‚ÄúObjetos‚Äù

Muestra predicci√≥n del modelo

Superpone la etiqueta y la confianza

Muestra FPS del sistema

Pesta√±a 2: ‚ÄúVelocidad‚Äù

Muestra bounding boxes de cada persona

Dibuja centroides

Muestra velocidad en px/s

# 3.6. Flujo Completo del Sistema

```mermaid
flowchart TD

    %% Nodos principales
    CAM[Camara]
    GRAB[CamGrabber - Frame Compartido]

    PRED[PredictorThread - Clasificacion]
    SPEED[PeopleSpeedThread - Tracking y Velocidad]

    UI[Streamlit UI]

    %% Indicador de Tracks Activos
    TRACKS[Tracks Activos]

    %% Flujo
    CAM --> GRAB

    GRAB --> PRED
    GRAB --> SPEED

    PRED --> UI
    SPEED --> UI

    SPEED --> TRACKS


```

Conclusiones del Punto 3

Se implement√≥ un sistema completo de visi√≥n artificial en tiempo real.

Se integraron dos modelos paralelos:

Clasificaci√≥n de herramientas

Detecci√≥n + velocidad de personas

Los hilos funcionan de manera segura mediante locks y sem√°foros.

La interfaz en Streamlit es clara, funcional y permite alternar entre vistas sin detener la c√°mara.

Sistema apto para laboratorios inteligentes, rob√≥tica o vigilancia.












# 4. Despliegue de la Aplicaci√≥n (Docker + Streamlit WebApp)

Este proyecto fue completamente contenedorizado, ejecutado y desplegado usando Docker y Streamlit, cumpliendo todos los requisitos del cuarto punto del entregable. A continuaci√≥n se muestra el procedimiento completo.

#  4.1. Construcci√≥n del contenedor Docker

El proyecto incluye un Dockerfile totalmente funcional.
Para construir la imagen localmente:
```python
docker build -t streamlit-detector .

```
Una vez finalizada la compilaci√≥n, confirmar que la imagen existe:
```python
docker images
```

 La imagen debe aparecer como streamlit-detector.

 <img width="1280" height="650" alt="image" src="https://github.com/user-attachments/assets/c155f91d-423f-4be8-b6ae-cb07151bbf1b" />


 # 4.2. Ejecuci√≥n local del contenedor

Para ejecutar el contenedor en tu propio equipo, us√© el siguiente comando:

docker run -p 8501:8501 --name visionapp streamlit-detector


Luego, abrir en el navegador:

 http://localhost:8501

Donde se cargan simult√°neamente:

- Detector de Velocidad (MediaPipe + tracking)

- Detector de Objetos (modelo simple entrenado)

- Interfaz Streamlit con ambas vistas lado a lado

### 4.3. Despliegue de la imagen en Docker Hub

La imagen final fue subida al repositorio p√∫blico:

Docker Hub:
 https://hub.docker.com/r/jefersonmvp/streamlit-detector

Para descargarla y ejecutarla desde cualquier equipo:
```python
docker pull jefersonmvp/streamlit-detector
docker run -p 8501:8501 jefersonmvp/streamlit-detector
```

#  4.4. Despliegue de la aplicaci√≥n v√≠a Streamlit Web

La aplicaci√≥n tambi√©n se despliega v√≠a Streamlit Web, permitiendo acceso desde navegador sin instalaci√≥n local:

Contiene:

Interfaz doble (Velocidad + Objetos)

Hilos independientes

FPS en tiempo real

Sincronizaci√≥n entre pipelines

Procesamiento simult√°neo por la misma c√°mara

(https://hub.docker.com/r/jefersonmvp/streamlit-detector)

# 4.5. Evidencias del despliegue
üîß Ejecuci√≥n correcta del contenedor

<img width="1280" height="655" alt="image" src="https://github.com/user-attachments/assets/47f3da5f-094b-4f9a-a61a-07af2699ccd2" />

 Streamlit funcionando con doble vista

<img width="1278" height="855" alt="image" src="https://github.com/user-attachments/assets/71bce428-0eb8-4870-980e-3118a7bba636" />

<img width="1280" height="655" alt="image" src="https://github.com/user-attachments/assets/e72dd60d-f3a1-46ea-8d33-16bcd378cc01" />

 Detector de Objetos funcionando

<img width="1280" height="574" alt="image" src="https://github.com/user-attachments/assets/2770e177-0901-4268-83f2-b606ad2080eb" />

<img width="1280" height="554" alt="image" src="https://github.com/user-attachments/assets/5401add8-41dc-467a-88cc-d0fe7c2eba9e" />

<img width="1280" height="606" alt="image" src="https://github.com/user-attachments/assets/59060e1d-bb4a-475e-870f-ae1de67f5649" />

<img width="1280" height="621" alt="image" src="https://github.com/user-attachments/assets/4534a711-4fd3-4616-8527-ced27c50efb7" />

<img width="1280" height="598" alt="image" src="https://github.com/user-attachments/assets/70ba03c7-0d02-4238-9f6c-a810ccc9c485" />

<img width="1280" height="574" alt="image" src="https://github.com/user-attachments/assets/967fddb4-cb3f-4e42-a7c1-76accb72dcae" />

<img width="1280" height="641" alt="image" src="https://github.com/user-attachments/assets/72aad00c-4cb7-46a1-bf75-d13222009a86" />

<img width="1280" height="596" alt="image" src="https://github.com/user-attachments/assets/af524f05-e7d2-4f8c-bdfa-3b1d60e97541" />

<img width="1280" height="636" alt="image" src="https://github.com/user-attachments/assets/64f39c9f-a317-4861-a963-a2b6b4036e14" />


Detector de Velocidad funcionando

<img width="1176" height="864" alt="image" src="https://github.com/user-attachments/assets/be4cc872-133c-4071-9db4-f819dee178e8" />

<img width="1278" height="855" alt="image" src="https://github.com/user-attachments/assets/e6875ffc-49e9-4fec-8246-c598ee9faff4" />


### 4.6. Conclusiones del despliegue

El proyecto es completamente portable gracias a Docker.

La aplicaci√≥n puede ejecutarse sin dependencias en cualquier m√°quina.

El c√≥digo integra simult√°neamente dos sistemas avanzados de visi√≥n por computador en producci√≥n.

La documentaci√≥n y el despliegue cumplen todos los requisitos del punto 4 del entregable.
